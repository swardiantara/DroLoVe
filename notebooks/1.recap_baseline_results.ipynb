{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Data Kuliah\\S2 ITS\\Semester 6\\IEEE Access\\DroMoLog\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Data Kuliah\\S2 ITS\\Semester 6\\IEEE Access\\DroMoLog\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def build_recap_multitask(model, source_dir, output_dir, setting='overall'):\n",
    "    recap_overall = pd.DataFrame()\n",
    "    recap_per_class = pd.DataFrame()\n",
    "    dataset_dirs = os.listdir(source_dir)\n",
    "    for dataset_dir in dataset_dirs:\n",
    "        dataset = dataset_dir\n",
    "        dataset_path = os.path.join(source_dir, dataset_dir)\n",
    "        encoders = os.listdir(dataset_path)\n",
    "        for encoder in encoders:\n",
    "            encoder_path = os.path.join(dataset_path, encoder)\n",
    "            class_weights = os.listdir(encoder_path)\n",
    "            for weight in class_weights:\n",
    "                weight_path = os.path.join(encoder_path, weight)\n",
    "                losses = os.listdir(weight_path)\n",
    "                for loss in losses:\n",
    "                    loss_path = os.path.join(weight_path, loss)\n",
    "                    poolings = os.listdir(loss_path)\n",
    "                    for pooling in poolings:\n",
    "                        pool_path = os.path.join(loss_path, pooling)\n",
    "                        n_layers = os.listdir(pool_path)\n",
    "                        for n_layer in n_layers:\n",
    "                            layer_path = os.path.join(pool_path, n_layer)\n",
    "                            n_heads = os.listdir(layer_path)\n",
    "                            for n_head in n_heads:\n",
    "                                head_path = os.path.join(layer_path, n_head)\n",
    "                                bidirectionals = os.listdir(head_path)\n",
    "                                for bidirectional in bidirectionals:\n",
    "                                    bidirectional_path = os.path.join(head_path, bidirectional)\n",
    "                                    files = os.listdir(bidirectional_path)\n",
    "                                    eval_report_path = os.path.join(bidirectional_path, files[1])\n",
    "                                    scenario_path = os.path.join(bidirectional_path, files[4])\n",
    "                                    with open(eval_report_path) as eval_report_file:\n",
    "                                        eval_report = json.load(eval_report_file)\n",
    "                                        with open(scenario_path) as scenario_json_file:\n",
    "                                            scenario = json.load(scenario_json_file)\n",
    "                                            if setting == 'overall':\n",
    "                                                prediction_path = os.path.join(bidirectional_path, 'prediction.xlsx')\n",
    "                                                if os.path.exists(prediction_path):\n",
    "                                                    prediction_df = pd.read_excel(prediction_path)\n",
    "                                                else:\n",
    "                                                    prediction_df = pd.read_csv(os.path.join(bidirectional_path, 'prediction.csv'))\n",
    "                                                    \n",
    "                                                confidence_avg = prediction_df['prob'].mean()\n",
    "                                                confidence_std = prediction_df['prob'].std()\n",
    "                                                accuracy = float(round(eval_report['accuracy'] * 100, 5))\n",
    "                                                precision = float(round(eval_report['weighted_avg']['precision'] * 100, 5))\n",
    "                                                recall = float(round(eval_report['weighted_avg']['recall'] * 100, 5))\n",
    "                                                f1_score = float(round(eval_report['weighted_avg']['f1-score'] * 100, 5))\n",
    "                                                best_epoch = int(scenario['best_epoch'])\n",
    "                                                columns = ['dataset', 'encoder', 'n_layer', 'n_head', 'bidirectional', 'pooling', 'class_weight', 'scenario', 'best_epoch', 'accuracy', 'precision', 'recall', 'f1_score', 'confidence_avg', 'confidence_std']\n",
    "                                                row_list = [dataset, encoder, n_layer, n_head, bidirectional, pooling, weight, loss, best_epoch, accuracy, precision, recall, f1_score, confidence_avg, confidence_std]\n",
    "                                                scenario_df = pd.DataFrame([row_list], index=None, columns=columns)\n",
    "                                                recap_overall = pd.concat([recap_overall, scenario_df], ignore_index=True)\n",
    "                                                if not os.path.exists(output_dir):\n",
    "                                                    os.makedirs(output_dir)\n",
    "                                                recap_overall.to_excel(os.path.join(output_dir, f'recap_overall_{model}.xlsx'), index=False, float_format='%.5f')\n",
    "                                            else:\n",
    "                                                accuracy = float(round(eval_report['accuracy'] * 100, 5))\n",
    "                                                best_epoch = int(scenario['best_epoch'])\n",
    "                                                high_score = [float(round(eval_report['high'][key] * 100, 5)) for key in eval_report['high'].keys()]\n",
    "                                                low_score = [float(round(eval_report['low'][key] * 100, 5)) for key in eval_report['low'].keys()]\n",
    "                                                medium_score = [float(round(eval_report['medium'][key] * 100, 5)) for key in eval_report['medium'].keys()]\n",
    "                                                normal_score = [float(round(eval_report['normal'][key] * 100, 5)) for key in eval_report['normal'].keys()]\n",
    "                                                columns = ['dataset', 'encoder', 'n_layer', 'n_head', 'bidirectional', 'pooling', 'class_weight', 'scenario', 'best_epoch', 'accuracy', 'high_precision', 'high_recall', 'high_f1_score', 'medium_precision', 'medium_recall', 'medium_f1_score', 'low_precision', 'low_recall', 'low_f1_score', 'normal_precision', 'normal_recall', 'normal_f1_score']\n",
    "                                                row_list = [dataset, encoder, n_layer, n_head, bidirectional, pooling, weight, loss, best_epoch, accuracy, high_score[0], high_score[1], high_score[2], medium_score[0], medium_score[1], medium_score[2], low_score[0], low_score[1], low_score[2], normal_score[0], normal_score[1], normal_score[2]]\n",
    "                                                scenario_df = pd.DataFrame([row_list], index=None, columns=columns)\n",
    "                                                recap_per_class = pd.concat([recap_per_class, scenario_df], ignore_index=True)\n",
    "                                                recap_per_class.to_excel(os.path.join(output_dir, f'recap_per_class_{model}.xlsx'), index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Own Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'multitask_15'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'baseline'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'per_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State-of-the-art Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'transsentlog_15'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'transsentlog'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'per_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'neurallog_15'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'neurallog'\n",
    "source_dir = os.path.join('experiments', model)\n",
    "output_dir = os.path.join('experiments', 'recap', model)\n",
    "build_recap_multitask(model, source_dir, output_dir, 'per_class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
